{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import musicbrainzngs\n",
    "import sqlalchemy\n",
    "from sqlalchemy import text\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from numpy import NaN\n",
    "import time\n",
    "import logging\n",
    "logging.basicConfig(filename='info.log', level=logging.INFO)\n",
    "from datetime import datetime\n",
    "from ratelimit import limits,sleep_and_retry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inital setup\n",
    "- load env variables\n",
    "- create connection to the sql database\n",
    "- create a spotify API client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Thirty_SECONDS = 30\n",
    "\n",
    "@sleep_and_retry\n",
    "@limits(calls=60, period=Thirty_SECONDS)\n",
    "def call_api():\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musicbrainzngs.set_useragent('application-project', '0.0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# token = os.environ.get(\"ENV_VARIABLE\")\n",
    "\n",
    "SPOTIFY_CLIENT_ID = os.environ.get(\"SPOTIFY_CLIENT_ID\")\n",
    "SPOTIFY_CLIENT_SECRET = os.environ.get(\"SPOTIFY_CLIENT_SECRET\")\n",
    "LAST_FM_API_KEY = os.environ.get(\"LAST_FM_API\")\n",
    "\n",
    "SQL_USERNAME = os.environ.get('SQL_USERNAME')\n",
    "SQL_PASSWORD = os.environ.get('SQL_PASSWORD')\n",
    "SQL_SCHEMA=os.environ.get('SQL_SCHEMA')\n",
    "SQL_TABLE=os.environ.get('SQL_TABLE')\n",
    "SQL_DIALECT = os.environ.get('SQL_DIALECT')\n",
    "SQL_DIRVER = os.environ.get('SQL_DRIVER')\n",
    "SQL_HOST = os.environ.get('SQL_HOST')\n",
    "SQL_PORT = os.environ.get('SQL_PORT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine(f'{SQL_DIALECT}+{SQL_DIRVER}://{SQL_USERNAME}:{SQL_PASSWORD}@{SQL_HOST}:{SQL_PORT}')\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text('Create database if not exists eighties'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_credentials_manager = SpotifyClientCredentials(client_id=SPOTIFY_CLIENT_ID, client_secret=SPOTIFY_CLIENT_SECRET)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_power_df = pd.read_excel('chart-power-scores_80s.xlsx')\n",
    "chart_power_df = chart_power_df.applymap(lambda s: s.lower() if type(s) == str else s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_power_df = chart_power_df[['Song', 'Artist', 'Points']].groupby(['Song', 'Artist']).sum()\n",
    "chart_power_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_power_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genres(isrc, api_key=LAST_FM_API_KEY):\n",
    "    '''\n",
    "    Retrives the genres of a song via the Last FM API.\n",
    "\n",
    "    First the isrc number is used to retrieve the musicbrainz id via the musicbraniz API. \n",
    "    This is used to retrive the genres later on from the Last FM API.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    isrc: string\n",
    "        ISRC number of the song\n",
    "\n",
    "    api_key: string\n",
    "        API key for the Last FM API\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    genre_list: string\n",
    "        string that contains the genres in a list\n",
    "    '''\n",
    "    # print(f'Get genre for isrc: {isrc}')\n",
    "    genre_list = ''\n",
    "    try:\n",
    "        # Use musicbrainz to get the musicbraniz id (https://musicbrainz.org/doc/MusicBrainz_API)\n",
    "        recordings = musicbrainzngs.get_recordings_by_isrc(isrc)\n",
    "        isrcs = recordings['isrc'] if 'isrc' in recordings else ''\n",
    "        recording_list = isrcs['recording-list'] if 'recording-list' in isrcs else ''\n",
    "        # recording_list = musicbrainzngs.get_recordings_by_isrc(isrc)['isrc']['recording-list']\n",
    "    except musicbrainzngs.ResponseError as e:\n",
    "        cause = str(e.cause)\n",
    "        if cause.find('404') == -1:\n",
    "            print(cause)\n",
    "        return genre_list\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return genre_list\n",
    "    \n",
    "    # time.sleep(1)\n",
    "\n",
    "    if len(recording_list) == 0:\n",
    "        return genre_list\n",
    "    elif len(recording_list) > 1:\n",
    "        print(f'Multiple recordings with isrc: {isrc}')\n",
    "\n",
    "    if 'id' in recording_list[0]:\n",
    "        mbid = recording_list[0]['id']\n",
    "    else:\n",
    "        return genre_list\n",
    "\n",
    "    # Use Last FM to get the genres (https://www.last.fm/api/show/track.getInfo)\n",
    "    url = f\"http://ws.audioscrobbler.com/2.0/?method=track.getInfo&api_key={api_key}&mbid={mbid}&format=json\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        data = json.loads(response.text)\n",
    "    except Exception as e:\n",
    "        print('Failed to retrieve genres from the Last FM API')\n",
    "        print(e)\n",
    "        return genre_list\n",
    "    \n",
    "    track = data['track'] if 'track' in data else ''\n",
    "    toptags = track['toptags'] if 'toptags' in track else ''\n",
    "    if 'tag' in toptags:\n",
    "        genres = toptags['tag']\n",
    "        for genre in genres:\n",
    "            genre_list = f'{genre_list}{genre[\"name\"]},'\n",
    "        return genre_list[:len(genre_list)-1]\n",
    "    else:    \n",
    "        return genre_list\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_track_features(track, genre, features):\n",
    "    '''\n",
    "    Filters the relevant features of a track in returns them in JSON object.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    track: Object\n",
    "        Track returend by the spotify API\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    relevant_features: Object\n",
    "        JSON Object that contains the relevant featues\n",
    "    '''\n",
    "    external_ids = track['external_ids'] if 'external_ids' in track else {}\n",
    "    isrc = external_ids['isrc'] if 'isrc' in external_ids else NaN\n",
    "    artist_names = []\n",
    "\n",
    "    if 'artists' in track and type(track['artists']) == list:\n",
    "        for artist in track['artists']:\n",
    "            if 'name' in artist:\n",
    "                artist_names.append(artist['name'])\n",
    "    #         ids = []\n",
    "    #         for artist in track['artists']:\n",
    "                # if 'id' in artist:\n",
    "                    # ids.append(artist['id'])\n",
    "            # artists = sp.artists(ids)\n",
    "            # artists = artists['artists'] if 'artists' in artists else []\n",
    "            # if type(artists) == list:\n",
    "                #  for artist in artists:\n",
    "                    # genres = ','.join(artist['genres']) if 'genres' in artist else []\n",
    "            #         if 'name' in artist:\n",
    "            #              artist_names.append(artist['name'])\n",
    "\n",
    "    artist_names = ','.join(artist_names)\n",
    "    \n",
    "    if 'album' in track:\n",
    "        album = track['album']['name'] if 'name' in track['album'] else NaN\n",
    "        release_date = track['album']['release_date'] if 'release_date' in track['album'] else NaN\n",
    "        release_date_precision = track['album']['release_date_precision'] if 'release_date_precision' in track['album'] else NaN\n",
    "    else:\n",
    "         album = NaN\n",
    "         release_date = NaN\n",
    "         release_date_precision = NaN\n",
    "\n",
    "\n",
    "    track_name = track['name'] if 'name' in track else NaN\n",
    "    if track_name != NaN:\n",
    "        points = chart_power_df.loc[(chart_power_df.Song == track_name.lower()) & (chart_power_df.Artist == artist_names.lower())]['Points']\n",
    "        if points.empty:\n",
    "             points = NaN\n",
    "        else:\n",
    "            points = int(points)\n",
    "    else:\n",
    "         points = NaN\n",
    "\n",
    "\n",
    "    return {\n",
    "        'name': track_name,\n",
    "        'artists': artist_names,\n",
    "        'album': album,\n",
    "        'release_date': release_date,\n",
    "        'release_date_precision': release_date_precision,\n",
    "        'spotify_id': track['id'] if 'id' in track else NaN,\n",
    "        'chart_power': points,\n",
    "        'uri': track['uri'] if 'uri' in track else NaN,\n",
    "        'popularity': track['popularity'] if 'popularity' in track else NaN,\n",
    "        'genres': genre,\n",
    "        'danceability': features['danceability'] if 'danceability' in features else NaN,\n",
    "        'energy': features['energy'] if 'energy' in features else NaN,\n",
    "        'key': features['key'] if 'key' in features else NaN,\n",
    "        'loudness': features['loudness'] if 'loudness' in features else NaN,\n",
    "        'mode': features['mode'] if 'mode' in features else NaN,\n",
    "        'speechiness': features['speechiness'] if 'speechiness' in features else NaN,\n",
    "        'acousticness': features['acousticness'] if 'acousticness' in features else NaN,\n",
    "        'instrumentalness': features['instrumentalness'] if 'instrumentalness' in features else NaN,\n",
    "        'liveness': features['liveness'] if 'liveness' in features else NaN,\n",
    "        'valence': features['valence'] if 'valence' in features else NaN,\n",
    "        'tempo': features['tempo'] if 'tempo' in features else NaN,\n",
    "        'duration_ms': features['duration_ms'] if 'duration_ms' in features else NaN,\n",
    "        'time_signature': features['time_signature'] if 'time_signature' in features else NaN,\n",
    "        'isrc': isrc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_to_sql(df: pd.DataFrame, table_name=SQL_TABLE, schema=SQL_SCHEMA, if_exists='replace'):\n",
    "    '''\n",
    "    Saves the DataFrame in the SQL Database\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    df: pd.DataFrame\n",
    "        DataFrame that should be saved\n",
    "\n",
    "    table_name: string; default=SQL_TABLE (.env)\n",
    "        Table name the DataFrame should be saved in.\n",
    "\n",
    "    schema: string; default=SQL_SCHMEA (.env)\n",
    "        Schema that should be used for the database\n",
    "\n",
    "    if_exists: string; default=\"replace\"\n",
    "        Action that should be performed if the specified table already exists. Possible values are \"replace\", \"fail\", \"append\".\n",
    "    '''\n",
    "    try:\n",
    "        df.to_sql(table_name, engine, schema=schema, if_exists=if_exists)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df_from_sql(table_name=SQL_TABLE, schema=SQL_SCHEMA):\n",
    "    '''\n",
    "    Reads a SQL table and saves it into a DataFrame.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    table_name: string; default=SQL_TABLE (.env)\n",
    "        Name of the table in the database\n",
    "\n",
    "    schema: string; default=SQL_SCHEMA (.env)\n",
    "        Name of the SQL schmea\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: pd.DataFrame\n",
    "        SQL table in a DatFrame\n",
    "    '''\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            return pd.read_sql_table(table_name, con=connection, schema=schema)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make initial request to get total number of results\n",
    "def get_number_of_tracks(release_year, start_letters, genre):\n",
    "    '''\n",
    "    Retrieves the number of tracks the spotfiy API returns for a specific query.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    release_year: int\n",
    "        Year the tracks were released\n",
    "\n",
    "    start_letters: string\n",
    "        Letters the songs start with\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    num: int\n",
    "        Number of tracks that spotify has data for. The max number is 1000. If 1000 is returned, it is possible that the number is higher.\n",
    "    '''\n",
    "    try:\n",
    "        call_api()\n",
    "        result = sp.search(q=f'year:{release_year} track:{start_letters}* genre:{genre}', type='track', limit=1, offset=0, market='DE')\n",
    "        tracks = result['tracks'] if 'tracks' in result else ''\n",
    "        return tracks['total'] if 'total' in tracks else 0\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def req_query_tracks(release_year, genres, start_letters = '', limit=50):\n",
    "    '''\n",
    "    Recursivley queries all tracks spotify returns for a specific query.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    release_year: int\n",
    "        Year the tracks were released\n",
    "\n",
    "    start_letters: string, default=''\n",
    "        Letters the songs start with\n",
    "    \n",
    "    limit: int; default=50\n",
    "        Number of tracks that should be queried at once. Max number is 50\n",
    "    '''\n",
    "    global df\n",
    "    alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    if type(genres) == str:\n",
    "        genres = [genres]\n",
    "    for genre in genres:\n",
    "        for letter in alphabet:\n",
    "            letters = start_letters + letter\n",
    "            total_results = get_number_of_tracks(release_year, letters, genre)\n",
    "            if total_results < 1000:\n",
    "                # print(release_year, letters, genre, total_results)\n",
    "                logging.info(f'{release_year}-{letters}-{genre}-{total_results}')\n",
    "                # Loop through results and retrieve tracks\n",
    "                offset = 0\n",
    "\n",
    "                while offset < total_results:\n",
    "                    try:\n",
    "                        track_features = []\n",
    "                        call_api()\n",
    "                        result = sp.search(q=f'year:{release_year} track:{letters}* genre:{genre}', type='track', limit=limit, offset=offset)\n",
    "                        tracks = result['tracks'] if 'tracks' in result else ''\n",
    "                        if 'items' in tracks:\n",
    "                            tracks_50_chunks = []\n",
    "                            for i in range(0, len(tracks['items']), limit):\n",
    "                                x = i\n",
    "                                tracks_50_chunks.append(tracks['items'][x:x+limit])\n",
    "                            for tracks_50 in tracks_50_chunks:\n",
    "                                ids = []\n",
    "                                for track in tracks_50:\n",
    "                                    ids.append(track['id'])\n",
    "                                call_api()\n",
    "                                features_50 = sp.audio_features(ids)\n",
    "                                for track in tracks['items']:\n",
    "                                    for feature in features_50:\n",
    "                                        if(feature['id'] == track['id']):\n",
    "                                            features = filter_track_features(track, genre, feature)\n",
    "                                            track_features.append(features)\n",
    "                            offset += limit\n",
    "                            df = pd.concat([df, pd.DataFrame(track_features)], ignore_index=True)\n",
    "                        else:\n",
    "                            continue\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "            else:\n",
    "                req_query_tracks(release_year, genre, letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_api()\n",
    "result = sp.search(q='year:1981')\n",
    "tracks = result['tracks'] if 'tracks' in result else ''\n",
    "if 'items' in tracks:\n",
    "    for track in tracks['items']:\n",
    "        for artist in track['artists']:\n",
    "            print(sp.artist(artist['id'])['genres'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['name', 'artists', 'album', 'release_date', 'release_date_precision', 'chart_power', 'spotify_id', 'uri', 'popularity', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature', 'isrc', 'genres']\n",
    "df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up query parameters\n",
    "query = 'year:1980'\n",
    "limit = 1\n",
    "offset = 0\n",
    "\n",
    "# Make initial request to get total number of results\n",
    "result = sp.search(q=query, type='track', limit=1, offset=0, market='DE')\n",
    "total_results = result['tracks']['total']\n",
    "\n",
    "# Loop through results and retrieve tracks\n",
    "while offset < 10:\n",
    "    call_api()\n",
    "    result = sp.search(q=query, type='track', limit=limit, offset=offset, market='DE')\n",
    "    track_features = []\n",
    "    # 50 chunks\n",
    "    tracks_50_chunks = []\n",
    "    for i in range(0, len(result['tracks']['items']), 50):\n",
    "        x = i\n",
    "        tracks_50_chunks.append(result['tracks']['items'][x:x+50])\n",
    "    for tracks_100 in tracks_50_chunks:\n",
    "        ids = []\n",
    "        for track in tracks_100:\n",
    "            ids.append(track['id'])\n",
    "        call_api()\n",
    "        features_100 = sp.audio_features(ids)\n",
    "        for track in tracks_100:\n",
    "            for feature in features_100:\n",
    "                if(feature['id'] == track['id']):\n",
    "                    features = filter_track_features(track, 'rock', feature)\n",
    "                    track_features.append(features)\n",
    "    offset += limit\n",
    "    df = pd.concat([df, pd.DataFrame(track_features)], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "call_api()\n",
    "genres = sp.recommendation_genre_seeds()['genres']\n",
    "for year in range(1980, 1986):\n",
    "    req_query_tracks(year, genres, '')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any duplicated track( a track may have more than 1 genre)\n",
    "# these should be join together later (e.g.genres:pop,country)\n",
    "df['isrc'].duplicated\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_api()\n",
    "genres = sp.recommendation_genre_seeds()['genres']\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "#start_time = datetime.now() \n",
    "#for year in range(1980, 1985):\n",
    "#    req_query_tracks(year, genres[0:3], '')\n",
    "#end_time = datetime.now()         \n",
    "#print('Duration: {}'.format(end_time - start_time))\n",
    "\n",
    "#threading:\n",
    "start_time = datetime.now() \n",
    "\n",
    "threads= []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    for year in range(1981, 1982):\n",
    "        threads.append(executor.submit(req_query_tracks, year, genres))\n",
    "        \n",
    "    for task in as_completed(threads):\n",
    "        print(task.result()) \n",
    "\n",
    "end_time = datetime.now()         \n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_1980 = df.to_csv(\"track_1981.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
