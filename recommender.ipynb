{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel, polynomial_kernel, sigmoid_kernel, rbf_kernel, laplacian_kernel, chi2_kernel, euclidean_distances, manhattan_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/DE/data-neu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were a lot of duplicate values.."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null values for the Chart Power are valid, because not every song was in the Charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First group the songs by the spotify id. This brings together all instances with different genres but same spotify id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_spotify_id = df.copy()\n",
    "by_spotify_id = by_spotify_id.groupby('spotify_id').agg({\n",
    "    'genres': list,\n",
    "    'name': list,\n",
    "    'artists': list,\n",
    "    'album': list,\n",
    "    'release_date': list,\n",
    "    'release_date_precision': list,\n",
    "    'uri': list,\n",
    "    'isrc':list,\n",
    "    'chart_power': list, \n",
    "    'popularity': list, \n",
    "    'danceability': list, \n",
    "    'energy': list,\n",
    "    'key': list, \n",
    "    'loudness': list, \n",
    "    'mode': list, \n",
    "    'speechiness': list, \n",
    "    'acousticness': list, \n",
    "    'instrumentalness': list, \n",
    "    'liveness': list, \n",
    "    'valence': list,\n",
    "    'tempo': list, \n",
    "    'duration_ms': list, \n",
    "    'time_signature': list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_spotify_id.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then reduce all categorical features such that there are no duplicated values in an instance for one feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_list(elements, string_return = True):\n",
    "    '''\n",
    "    Removes duplicate elements in a list\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    elements: list\n",
    "        List that should be reduced\n",
    "\n",
    "    string_return: boolean; default=True\n",
    "        Whether a list with just one element should be returned as string or list\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    unique_elements: list or str\n",
    "    \n",
    "    '''\n",
    "    unique_elements = []\n",
    "    for element in elements:\n",
    "        if element not in unique_elements:\n",
    "            unique_elements.append(element)\n",
    "    if (len(unique_elements) == 1 and string_return):\n",
    "        return unique_elements[0]\n",
    "    return unique_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by_spotify_id['name'] = by_spotify_id['name'].agg(reduce_list)\n",
    "# by_spotify_id['isrc'] = by_spotify_id['isrc'].agg(reduce_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_spotify_id.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_release_year_index(release_dates):\n",
    "    '''\n",
    "    Returns the index of the release year.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    release_dates: List\n",
    "        List that contains all dates a version of the song was released.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    min_index: number\n",
    "        Index in the list that contains the oldest release year.\n",
    "    '''\n",
    "    release_year = []\n",
    "    for date in release_dates:\n",
    "        release_year.append(int(date[:4]))\n",
    "    return (np.array(release_year)).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_oldest_song(df, isrc_flag=False):\n",
    "    features = ['artists', 'album', 'release_date_precision', 'uri', 'release_date', 'chart_power', 'popularity', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "                'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature', 'name']\n",
    "\n",
    "    if isrc_flag:\n",
    "        features.append('genres')\n",
    "        features.append('spotify_id')\n",
    "    else:\n",
    "        features.append('isrc')\n",
    "    df_copy = df.copy()\n",
    "    for index, instance in df_copy.iterrows():\n",
    "        if type(instance['release_date']) == list:\n",
    "            min_index = get_release_year_index(instance['release_date'])\n",
    "            for feature in features:\n",
    "                if type(instance[feature] == list):\n",
    "                    df_copy.loc[index, feature] = instance[feature][min_index]\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_spotify_id = select_oldest_song(by_spotify_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_spotify_id.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by_spotify_id.to_csv('data/checkpoint/by_spotify_id_oldest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by_spotify_id = pd.read_csv('data/checkpoint/by_spotify_id_oldest.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to group all the songs by the isrc number since this should be the unique identifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_isrc = by_spotify_id.copy()\n",
    "by_isrc.reset_index(inplace=True)\n",
    "by_isrc = by_isrc.groupby('isrc').agg({\n",
    "    'genres': list,\n",
    "    'name': list,\n",
    "    'artists': list,\n",
    "    'album': list, \n",
    "    'release_date': list,\n",
    "    'release_date_precision': list,\n",
    "    'uri': list,\n",
    "    'spotify_id':list,\n",
    "    'chart_power': list, \n",
    "    'popularity': list, \n",
    "    'danceability': list, \n",
    "    'energy': list,\n",
    "    'key': list, \n",
    "    'loudness': list, \n",
    "    'mode': list, \n",
    "    'speechiness': list, \n",
    "    'acousticness': list, \n",
    "    'instrumentalness': list, \n",
    "    'liveness': list, \n",
    "    'valence': list,\n",
    "    'tempo': list, \n",
    "    'duration_ms': list, \n",
    "    'time_signature': list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_isrc.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_isrc = select_oldest_song(by_isrc, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_isrc.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by_isrc.to_csv('data/checkpoint/by_isrc_oldest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by_isrc = pd.read_csv('data/checkpoint/by_isrc_oldest.csv')\n",
    "# by_isrc.set_index('isrc', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special_cases = by_isrc.copy()\n",
    "# special_cases['name'] = special_cases['name'].agg(reduce_list, string_return=False)\n",
    "# special_cases = special_cases[special_cases['name'].apply(len) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special_cases.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beispiel eines special cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.isrc == 'AUCI10753909']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtern der Special cases: Wirklich relevant sind lediglich Lieder aus Deutschland, USA, UK, Italien und Schweden. Daher werden zunächst alle anderen Lieder herausgefiltert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_codes = ['DE', 'IT', 'GB', 'US', 'SE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant_special_cases = pd.DataFrame()\n",
    "# sum_entries = 0\n",
    "# for code in country_codes:\n",
    "#     rsc_country = special_cases[special_cases.index.str.startswith(code)]\n",
    "#     sum_entries += rsc_country.shape[0]\n",
    "#     relevant_special_cases = pd.concat([relevant_special_cases, rsc_country])\n",
    "# sum_entries == relevant_special_cases.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Old shape: {special_cases.shape}')\n",
    "# special_cases.drop(index=list(relevant_special_cases.index.values), inplace=True)\n",
    "# print(f'New shape: {special_cases.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant_special_cases.shape[0] + special_cases.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant_special_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant_special_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = special_cases.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by_isrc_copyy = by_isrc_copyy.drop(index=indices.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = by_isrc_copyy['name'].apply(lambda x: type(x) != str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by_isrc.loc[s.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_isrc['year'] = by_isrc['release_date'].apply(lambda x: int(x[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_isrc['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_songs_from_2023 = list(by_isrc[by_isrc['year'] == 2023].index)\n",
    "by_isrc.drop(index=index_songs_from_2023, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_isrc['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_isrc.release_date_precision = by_isrc.release_date_precision.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_isrc.to_csv('data/checkpoint/by_isrc_oldest.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame which contains only the relevant features for the recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommender = by_isrc.drop(columns=['artists', 'genres', 'album', 'release_date', 'release_date_precision', 'chart_power', 'uri', 'popularity', 'name', 'spotify_id'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicate values.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommender.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommender.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommender.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were some duplicates.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommender.head().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data, so every feature has the same influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_recommender_scaled = scaler.fit_transform(df_recommender)\n",
    "df_recommender_scaled = pd.DataFrame(df_recommender_scaled, columns=df_recommender.columns, index = df_recommender.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommender_scaled.reset_index(inplace=True)\n",
    "df_recommender.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommender_scaled.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommender_scaled.describe().T[['min', 'max']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert every genre to a feature. If a song is part of a genre it should contain the value 1 otherwise 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.crosstab(df['isrc'], df['genres'])\n",
    "# ct.reset_index(inplace=True)\n",
    "ct = ct.applymap(lambda x: 1 if x > 1 else x)\n",
    "ct.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ct.head().T)\n",
    "ct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctMinMax = ct.describe().T\n",
    "if (ctMinMax['min'].min() != 0) | (ctMinMax['min'].max() != 0) | (ctMinMax['max'].min() != 1) | (ctMinMax['max'].max() != 1):\n",
    "    print('Values are not scaled correctly')\n",
    "else:\n",
    "    print('Values are all scaled between 0 and 1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge both DataFrames together to create the Recommender System."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_merged = ct.merge(df_recommender_scaled, on=['isrc'], how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_merged.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_merged.set_index(['isrc'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ct_merged.head().T)\n",
    "ct_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_merged.to_csv('data/checkpoint/ct_merged.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall there are 124 features used for the Recommendation system."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different distance measures / similarity functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_tracks_kernel(track: str, recommender_function, distance: bool = False):\n",
    "    '''\n",
    "    Recommends tracks that are similar to the provided track.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    track: str\n",
    "        Provided track\n",
    "\n",
    "    df: pd.DataFrame\n",
    "        DataFrame used for the Recommendation\n",
    "    \n",
    "    '''\n",
    "    global ct_merged\n",
    "\n",
    "    global by_isrc\n",
    "\n",
    "    ids = list(by_isrc[by_isrc.name == track].index)\n",
    "\n",
    "    if (len(ids)):\n",
    "        kernel_array = recommender_function(ct_merged, ct_merged[ct_merged.index == ids[0]])\n",
    "        kernel_df = pd.DataFrame(kernel_array, index=ct_merged.index)\n",
    "\n",
    "        kernel_df = kernel_df.rename(columns={0: 'Score'})\n",
    "        kernel_df = kernel_df.merge(by_isrc, how='left', on='isrc')\n",
    "        display(kernel_df.sort_values(by='Score', ascending=distance).head(6))\n",
    "        return kernel_df\n",
    "    else:\n",
    "        print('Error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_functions(track):\n",
    "    kernel_functions = [cosine_similarity]\n",
    "    distance_functions = [euclidean_distances, manhattan_distances]\n",
    "    result = {}\n",
    "    for kernel_function in kernel_functions:\n",
    "        display(kernel_function.__name__)\n",
    "        result[kernel_function.__name__] = recommend_tracks_kernel(track, kernel_function, False)\n",
    "\n",
    "    for distance_function in distance_functions:\n",
    "        display(distance_function.__name__)\n",
    "        result[distance_function.__name__] = recommend_tracks_kernel(track, distance_function, True)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_isrc.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = try_functions(\"I'm Still Standing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "application-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
